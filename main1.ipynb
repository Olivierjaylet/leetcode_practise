{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\k'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\k'\n",
      "C:\\Users\\Olivier\\AppData\\Local\\Temp\\ipykernel_7064\\2258130061.py:4: SyntaxWarning: invalid escape sequence '\\k'\n",
      "  df = pd.read_csv('kdt-NLANU-0.01.connlu.txt\\kdt-NLANU-0.01.connlu.txt',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>WORD</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS</th>\n",
       "      <th>XPOS</th>\n",
       "      <th>MORPH</th>\n",
       "      <th>HEAD</th>\n",
       "      <th>DEPREL</th>\n",
       "      <th>DEPS</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ҚТЖ</td>\n",
       "      <td>ҚТЖ</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>халықаралық</td>\n",
       "      <td>халықаралық</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>_</td>\n",
       "      <td>3</td>\n",
       "      <td>amod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>серіктестікті</td>\n",
       "      <td>серіктестік</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Case=Acc</td>\n",
       "      <td>4</td>\n",
       "      <td>dobj</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>кеңейтуде</td>\n",
       "      <td>кеңей</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Person=3|vbTense=Aor|vbVcCaus=True</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NUM</td>\n",
       "      <td>_</td>\n",
       "      <td>2</td>\n",
       "      <td>compound</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           WORD        LEMMA    POS   XPOS  \\\n",
       "1   1            ҚТЖ          ҚТЖ  PROPN  PROPN   \n",
       "2   2    халықаралық  халықаралық    ADJ    ADJ   \n",
       "3   3  серіктестікті  серіктестік   NOUN   NOUN   \n",
       "4   4      кеңейтуде        кеңей   VERB   VERB   \n",
       "6   1            160          160    NUM    NUM   \n",
       "\n",
       "                                MORPH HEAD    DEPREL DEPS MISC  \n",
       "1                                   _    4     nsubj    _    _  \n",
       "2                                   _    3      amod    _    _  \n",
       "3                            Case=Acc    4      dobj    _    _  \n",
       "4  Person=3|vbTense=Aor|vbVcCaus=True    0      root    _    _  \n",
       "6                                   _    2  compound    _    _  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"ID\", \"WORD\", \"LEMMA\", \"POS\", \"XPOS\", \"MORPH\", \"HEAD\", \"DEPREL\", \"DEPS\", \"MISC\"]\n",
    "\n",
    "# Read the file and convert it to a DataFrame\n",
    "df = pd.read_csv('kdt-NLANU-0.01.connlu.txt\\kdt-NLANU-0.01.connlu.txt', \n",
    "                 sep='\\t', \n",
    "                 names=columns, \n",
    "                 skip_blank_lines=True)\n",
    "\n",
    "# Drop rows where 'WORD' is NaN\n",
    "df = df.dropna(subset=['WORD'])\n",
    "\n",
    "df = df[df['POS'] != 'PUNCT']\n",
    "\n",
    "df['ID'] = df['ID'].astype(int)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all numeric strings with '10'\n",
    "def standardize_numbers(df_):\n",
    "    df_['WORD'] = df_['WORD'].apply(lambda x: '10' if x.isdigit() else x)\n",
    "    return df_\n",
    "df = standardize_numbers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_sentences = df_sentences.sample(n=1000, \\n                                   random_state=2)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentences(df_) : \n",
    "    \n",
    "    df_ = df_.copy() # copy the input df\n",
    "\n",
    "    # Grouping by ID and aggregating the words and POS tags\n",
    "    df_['sentence'] = df_.groupby((df_['ID'] == 1).cumsum())['WORD'].transform(lambda x: ' '.join(x))\n",
    "    df_['POS'] = df_.groupby((df_['ID'] == 1).cumsum())['POS'].transform(lambda x: ' '.join(x))\n",
    "\n",
    "    # Filter out rows where ID is 1, as they are not part of the final sentences\n",
    "    df_sentences = df_[df_['ID'] != 1][['sentence', 'POS']].reset_index(drop=True)\n",
    "\n",
    "    # Remove duplicates\n",
    "    df_sentences = df_sentences.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return df_sentences\n",
    "\n",
    "df_sentences = get_sentences(df)\n",
    "\"\"\"\n",
    "df_sentences = df_sentences.sample(n=1000, \n",
    "                                   random_state=2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences['length'] = df_sentences['sentence'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28771.000000\n",
       "mean       118.602794\n",
       "std         86.921846\n",
       "min          7.000000\n",
       "25%         55.000000\n",
       "50%         96.000000\n",
       "75%        158.000000\n",
       "max        865.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Sentence Length Distribution'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sentences['length'].plot(kind='hist', bins=50, title='Sentence Length Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293.0\n"
     ]
    }
   ],
   "source": [
    "print(df_sentences['length'].quantile(0.95))\n",
    "Q95 = df_sentences['length'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_longer_sentence(df) :\n",
    "    # Calculate the length of each sentence\n",
    "    df['length'] = df['sentence'].apply(len)\n",
    "\n",
    "    # Identify the index of the longest sentence\n",
    "    condition = (df_sentences['length']>Q95)\n",
    "\n",
    "    # Drop the longest sentence from the DataFrame\n",
    "    df = df.drop(df[condition].index)\n",
    "\n",
    "    # Optionally, you can drop the 'length' column if no longer needed\n",
    "    df = df.drop(columns='length')\n",
    "\n",
    "    return df\n",
    "\n",
    "df_sentences = delete_longer_sentence(df_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(df):\n",
    "    X_sent = df['sentence'].str.strip()\n",
    "    X_sent = X_sent.values\n",
    "\n",
    "    y_sent = df['POS'].str.strip()\n",
    "    y_sent = y_sent.values\n",
    "\n",
    "    return X_sent, y_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences.shape[0] # number of sentences\n",
    "\n",
    "X_sent, y_sent = get_values(df_sentences)\n",
    "\n",
    "max_sent_len=max([len(w) for w in X_sent])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sent, y_sent, test_size=0.1, random_state=42)\n",
    "\n",
    "# TfidVectorizer with words model\n",
    "vectorizer = TfidfVectorizer(lowercase=False, \n",
    "                            analyzer='word'\n",
    "                            )\n",
    "\n",
    "X = vectorizer.fit_transform(X_sent)\n",
    "\n",
    "dic = vectorizer.get_feature_names_out() # word dictionary\n",
    "dic = list(dic)\n",
    "\n",
    "\n",
    "num_word = len(dic)\n",
    "mx = X.T.dot(X) # word cooccurence matrix\n",
    "mx = mx.toarray() #.astype(np.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mx_sparse = sparse.csr_matrix(mx)\n",
    "mx_sparse # 6700 x 6700 sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_POS_tags(y) :\n",
    "    list_tags = []\n",
    "    for tag_list in y :\n",
    "        tags = tag_list.split()\n",
    "        for tag in tags :\n",
    "            if tag not in list_tags :\n",
    "                list_tags.append(tag)\n",
    "    return list_tags\n",
    "\n",
    "def set_up_POS_tag_encoder(list_tags) : \n",
    "    encoder_tag = LabelEncoder().fit(list_tags)\n",
    "    return encoder_tag\n",
    "\n",
    "list_tags = list_all_POS_tags(y = y_train)\n",
    "encoder_tag = LabelEncoder().fit(list_tags)\n",
    "\n",
    "\n",
    "#vec encoding of words\n",
    "def alpha_vec2(w, mx, max_sent_len, dic):\n",
    "        vec=np.zeros((max_sent_len,\n",
    "                      len(dic)))\n",
    "        \n",
    "        words = w.split()\n",
    "        for i in range(0, len(words)):\n",
    "\n",
    "                word = words[i]\n",
    "\n",
    "                if word in dic :\n",
    "                        #print(mx[dic.index(word)])\n",
    "                        vec[i]=mx[dic.index(word)]\n",
    "\n",
    "        vec = vec.astype('float16').flatten()\n",
    "        vec[vec == np.inf] = 0 \n",
    "        vec[vec == -np.inf] = 0\n",
    "        return vec\n",
    "\n",
    "\n",
    "encoder_tag = set_up_POS_tag_encoder(list_tags)\n",
    "#ordinal encoding of words\n",
    "\n",
    "def alpha_vec2ord(w, max_sent_len, encoder_tag):\n",
    "    vec=np.zeros(max_sent_len)\n",
    "    words = w.split()\n",
    "    encoded_tags = encoder_tag.transform(words)\n",
    "    for i in range(len(encoded_tags)) : \n",
    "        vec[i]=encoded_tags[i]\n",
    "\n",
    "    return vec.astype('int')\n",
    "\n",
    "#ordinal decoding of words\n",
    "def decode_vec(vec):\n",
    "    w=''.join([chr(int(v)) for v in vec if v!=0])\n",
    "    return w.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize\n",
    "X_sent_vec_train=[alpha_vec2(w, mx, max_sent_len, dic) for w in X_train]\n",
    "Y_sent_vec_train=[alpha_vec2ord(w, max_sent_len, encoder_tag) for w in y_train]\n",
    "\n",
    "X_sent_vec_test=[alpha_vec2(w, mx, max_sent_len, dic) for w in X_test]\n",
    "Y_sent_vec_test=[alpha_vec2ord(w, max_sent_len, encoder_tag) for w in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.    , 0.    , 0.0276, ..., 0.    , 0.    , 0.    ], dtype=float16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sent_vec_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model\n",
    "best_model=ExtraTreesClassifier(n_estimators=10, n_jobs=5, criterion='entropy', bootstrap=True)\n",
    "\n",
    "best_model.fit(X_sent_vec_train, Y_sent_vec_train)\n",
    "\n",
    "#Test\n",
    "predicts_test=best_model.predict(X_sent_vec_test)\n",
    "predicts_train=best_model.predict(X_sent_vec_train)\n",
    "test_acc=sum([sum(p==y)==max_sent_len for p,y in zip(predicts_test, Y_sent_vec_test)])/len(predicts_test)\n",
    "train_acc=sum([sum(p==y)==max_sent_len for p,y in zip(predicts_train, Y_sent_vec_train)])/len(predicts_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y =  [ 7  0  7 14  7  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  7  7  7  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 6 11  7  7  2 14 10 14  2  7  7  7  1 11  7]\n",
      "p =  [ 7  0  7  0  7  7 14  0 14  0  0  7  0  7  7]\n",
      "False\n",
      "y =  [7 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [10  0  7 14  7  0  7  7  0  7  0  7  7 14  2]\n",
      "p =  [11  7  7  7  7  7  0  7  7  0  0  7  0  0  0]\n",
      "False\n",
      "y =  [11 11  7 11 11  4  7  7  4 10 14  1 14  0  0]\n",
      "p =  [ 7  7  2 11  7  7  0 14  4  7  2 14  7  0 14]\n",
      "False\n",
      "y =  [11  7  1  8  8  7 14  0  0  0  0  0  0  0  0]\n",
      "p =  [7 7 7 7 0 7 0 0 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [11 11  7  7 14  1  7  0 14  3  0  0  0  0  0]\n",
      "p =  [ 7 14  7  0  0  7  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7  7  2  0  0  7 14  8  8  7  7 14 14 14  8]\n",
      "p =  [ 7  7  7  7  7  7 14  7  8  7  0  0  0  7 14]\n",
      "False\n",
      "y =  [10  1  7  7  0  7  7  7 14  1  7 14  7  4  7]\n",
      "p =  [ 7  7  7  7  7  7  0  7  0  7  7  7 14  4  7]\n",
      "False\n",
      "y =  [11 14  7  7 14  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [11  2 14  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11  4  1  0  7 14  4 14 14 14 10  7 14  8  0]\n",
      "p =  [ 0  7  7 14  7  7 14  7  7  7  7  7  7  8  7]\n",
      "False\n",
      "y =  [10 14  7 14 10 14  7 14 14  7 14  7  7 11 11]\n",
      "p =  [11  7  7  0 14  3  7  0 14  0 14  0  0  0  0]\n",
      "False\n",
      "y =  [ 8  7 11  7 11  0  7 11  7  7 11 11  7 11 11]\n",
      "p =  [8 7 7 7 7 7 0 0 0 7 0 0 0 0 0]\n",
      "False\n",
      "y =  [ 6 10  7 10  7 10 14  3  0  0  0  0  0  0  0]\n",
      "p =  [11  7  7  7  7  7  2 14  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11 11 11  4 11 11  7  7 14 14  7 14  0  0  0]\n",
      "p =  [10 11  7 11  7  7  7  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 0  7 10 10  7 14  7 14 14  3  1  0  7  7 14]\n",
      "p =  [10 10  2 14  3 14 14 11  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [12  1  7 14  4  0  7 14  8  7 14 14 14  0  7]\n",
      "p =  [11  7  7  7  0  0  7  7  7  7  7  7 14  7  0]\n",
      "False\n",
      "y =  [0 7 7 0 0 7 0 0 0 0 0 0 0 0 0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 2 10  7  7  0  7 14  0  7  0  0  7 14 14  0]\n",
      "p =  [10  7  7 14  7  0  0  0  7  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [10  1  0  7  7 14  7  7  7  7 14  7 11 11 14]\n",
      "p =  [10  1 11  7  7  1  7  7  0 11 14  0  0  0  0]\n",
      "False\n",
      "y =  [11 10  7 10 11  7 14  7 11  1 14  3 14  7 14]\n",
      "p =  [ 0  7 14 14  0  7  7  7 14  1 14  7 14  0  0]\n",
      "False\n",
      "y =  [11  7  7  7  7  7  7  0  7 14  3 14  3  0  0]\n",
      "p =  [ 7  0  0  7  7 11 11  0  7  7  7  0 14  0  0]\n",
      "False\n",
      "y =  [ 8  8  7 10  7  7  0 14  3  0  0  0  0  0  0]\n",
      "p =  [ 7  7  7  7  0 14  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [10  1 10  1  0 14  7 14 14 14 14 11 11  0  0]\n",
      "p =  [14  7 14  3  7 14 14 14 14 14  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7  0  0  7  7 14  7  7  7  7  7  7 14  1 14]\n",
      "p =  [11  7  7  7  7  7  0  7 14  0  7  0  0  0  0]\n",
      "False\n",
      "y =  [ 2 14  7  7  7 14  1 14  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11  7  7  7  7  7  7 14 14  3  0  0  0  0  0]\n",
      "p =  [ 7  7  7  7  0  7  7  7  0 14  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7 14  8  8  7  0  7 14  3 10  8  8  0  7  0]\n",
      "p =  [10  7  8  8  7  7  0  7  0  1  0  0  0  0  0]\n",
      "False\n",
      "y =  [10 10 11  7  0 10 14  1 14  3 14  7 14  1  7]\n",
      "p =  [ 7  7 14  7  7 14  0 14  0  0  0  0 14  0  0]\n",
      "False\n",
      "y =  [ 7  2 10  1 10  1 14  3  0  0  0  0  0  0  0]\n",
      "p =  [7 7 7 0 7 1 0 0 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [ 0  7  5  0  7  8  8  7  2 14  3 10  7  0  2]\n",
      "p =  [11  7  7 14 14  7  0  7  7  7  0  0  0  7  0]\n",
      "False\n",
      "y =  [11  7  0  7 14  0  7 10  7 14 14 11 11  0  0]\n",
      "p =  [11  7 11 14 14  7  7  7 14  7 14 14  0  0  0]\n",
      "False\n",
      "y =  [ 7  1 11  7  0 11  0 11 11  7  7  0  7  7 14]\n",
      "p =  [7 1 7 7 7 7 0 7 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [11 11 14  0 14  2 14 10  0  0 14 10 10  7 14]\n",
      "p =  [11 10 14  7  7  7  7  2 14  0  7  1  7  7 14]\n",
      "False\n",
      "y =  [ 7  8  4  8  7 11  0  7  7  7  8  7 11 11  7]\n",
      "p =  [ 7  7  7  7  7 14  7 14  0  0  7  0 14  0  7]\n",
      "False\n",
      "y =  [10  1  7 14 14  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [ 0  1  7  7  0  0  0 14  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [10  0  7  7  0  7  7  7 14 14  0  0  0  0  0]\n",
      "p =  [0 7 7 0 7 7 0 0 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [ 7 14  7 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7 14  0 14  0  7  7 14  7 10  0  0  0  0  0]\n",
      "p =  [10  7  7  7  7 14 11  0  7  4  0  7  7  0  0]\n",
      "False\n",
      "y =  [ 4  7 10  2 14  3  0  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 0  7  7  7 14 14 14 11  7  7 11 11  0  0  0]\n",
      "p =  [ 7 14  0  0  7  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11  0  7  7  7 11  7 14  7  7  7  7  0 14 14]\n",
      "p =  [ 2  7  7  7  7  7  0  7  7  1  7  7 14 14 14]\n",
      "False\n",
      "y =  [ 2  0  7 11  7 11  7  1 14  0  0  0  0  0  0]\n",
      "p =  [ 7 10 14  7  7 14 11  1  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7 14  3 10  8  7 14  3  0  0  0  0  0  0  0]\n",
      "p =  [11  7  7 14  7 14  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7  0  7  0  7  0  7  4  7 14  7 14  0  0  0]\n",
      "p =  [ 7  7  7  7  7  7  7  4  7  7 14  7 14  0  0]\n",
      "False\n",
      "y =  [10 11 11 14  9  0  4 11 11 14  9  0  0  0  0]\n",
      "p =  [10  7  0  0  7  7 14  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 2 14  8  8  1  7  0  0  0  0  0  0  0  0  0]\n",
      "p =  [10  7  6  7  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 4  1  7  7  7  0  7  7 14 10  0  7  4  7  7]\n",
      "p =  [ 7  7 11  0  7  7  0  7 14  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11  7  7  7 14  3  0  7  7  1  0  8  0  7  2]\n",
      "p =  [11  7 11  7 11 11  0  7  0  7  7  0 14 14  0]\n",
      "False\n",
      "y =  [10 14 14 14 14  1 10  7 14  3 10 14 11  0  0]\n",
      "p =  [ 7  0 14  7  7  7 14  7 14 14  0  0  0  0  0]\n",
      "False\n",
      "y =  [10  7  1  7  7 10  7  7 14  0  0  0  0  0  0]\n",
      "p =  [11  7  7  0  7  7  7  0 14 14  0  0  0  0  0]\n",
      "False\n",
      "y =  [11  7 14  1 11  2  0  7  7 14  7  7  7 14  0]\n",
      "p =  [11  7  7  7  7 14  7  7  7 14 14  0  0  0  0]\n",
      "False\n",
      "y =  [ 7  7  0  7 14  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7  7  7 10  0  7  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11 14  0  0  7  0  7  7 10  7  7  0 14  7  4]\n",
      "p =  [ 7  7  7 11  7  0  0  7  0  7  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7  7 14 11  7  2  7  8  7  7  4  7  7 14  7]\n",
      "p =  [ 7  7  7  7  0  7  7 14  7 14 14  7 14  0 14]\n",
      "False\n",
      "y =  [10  7 14  7 14  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [7 7 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [ 2  7 14  7  7  7 14  8  7  7  0  7  8 14  0]\n",
      "p =  [ 8  7  7  7  7 14  0  8  7  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 5  0  7 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [10  7  7  7  7  7 14  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11 11 11  7  0  7 10  7  1 14  3 14  3  0  0]\n",
      "p =  [10  7 14  7  7 14  3 10  1  7  0  0  0  0  0]\n",
      "False\n",
      "y =  [10  7 11  7  7 14 10  0  7 14  7  2  7 14  0]\n",
      "p =  [10  7  7  7  7  7 14  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 0  7  7  7  8 13 14  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 11  0  7  8  7  7  7  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [14  7 11 11  0  7 14 11  4 10  7 11 14  7  0]\n",
      "p =  [10  7  7 14  7  0  7  7  7  0  7  2  7  7  7]\n",
      "False\n",
      "y =  [ 0  7  7 10  7  7  1  7  7  4  7  7  8  8  7]\n",
      "p =  [ 7 14  7  0  7  7  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [10 10  7  7  7  4  7 14  0  7  0 14  3  0  0]\n",
      "p =  [ 2  0  7 11 11  4 11  0  7  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11  7 14  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 2  0  7  7  7  7 14  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 2 14  8  7  1  7  7  7  7  2 14  7 14  3  0]\n",
      "p =  [7 7 1 7 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [ 0  7 14  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 4 11 14  7 11 14  2 14  7  7 14 10  7 14  0]\n",
      "p =  [ 7 14  7 14  7 14  7 14  0  7 14 14  0  0  0]\n",
      "False\n",
      "y =  [10  7 10  7  7 14 14  0  0  0  0  0  0  0  0]\n",
      "p =  [10  7  7  7  7  7 14  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [12  0  7 14  0  8  7  7 14  0  0  0  0  0  0]\n",
      "p =  [ 7  7 14  0  7  7  2  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7  7  7 14  7 14  7 14  0 14  0  0  0  0  0]\n",
      "p =  [7 7 7 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [11  7 11  7 14  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11  7  7 11 11  7 14  7 11  7  7  1 14  7  7]\n",
      "p =  [11  0  0  7  7  7  7  7 14  7 14  0  0  0  0]\n",
      "False\n",
      "y =  [ 7  2  1 11  0 14  7  1 14  0  7  0  7 10 10]\n",
      "p =  [11  7 11 11  7  7  7 14  0  0 14  0  0  0  0]\n",
      "False\n",
      "y =  [ 7 14  1  8  7  7  7  7  0  7 14  0  0  0  0]\n",
      "p =  [ 7  7 14  8 14  7 14  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 2  7 14 14 14  1 14  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  7  7  7  7  7 14  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7 11 14  7  8  7 11 14  7 11 14  7  7 14  0]\n",
      "p =  [ 7 11  0  7  8  7  7  7  0  7  0  0  0  0  0]\n",
      "False\n",
      "y =  [11 11  7 11 11  7  7  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 0  7  7  7  7 14  7 14  3  3  1 11  7  4  7]\n",
      "p =  [11  4  7 14  3 11  7  7  7  7  7  0  7  4  0]\n",
      "False\n",
      "y =  [ 8  2  4  2 14 10 14  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7  7 14  3  7 14  0  0  0  0  0  0  0  0  0]\n",
      "p =  [0 7 7 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [14  7  1 10  7  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [ 0  7  1 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7  0  7 14 11  7  7  1  7  0  7 14  0  7 14]\n",
      "p =  [ 7 11  7  7  7  7  7  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11  7 10 14  7  7  7  7  0  7 14  0  7  7 14]\n",
      "p =  [11  7  7  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [10  7  2 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      "p =  [ 7 14 14  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [11  8  7  7  7 14  3  0  0  0  0  0  0  0  0]\n",
      "p =  [7 8 7 7 7 7 0 0 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [12  0  0  7 11  0  7  7 14  3 14  0  0  0  0]\n",
      "p =  [ 7  7  0  7 14  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 0  7  0  7  0 14  7  7  7 14  0 14  3  0  0]\n",
      "p =  [ 7 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 7  7  1 11  7 14  7  0 10  0  7 14  0  0  0]\n",
      "p =  [7 7 0 7 7 7 7 0 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [11 11  7  8  7  8  7  7 14  0  0  0  0  0  0]\n",
      "p =  [ 2  0  7  0  7  8  7  0 14  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [ 2 10  7 14 14  7  7 14  0  7  7  7  0  7  7]\n",
      "p =  [ 2 10  7 14 14  7 14  3  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [14 10  0 14  0  7 14  8  7  7  0 14  0  0  0]\n",
      "p =  [7 7 7 4 7 7 1 7 0 0 0 0 0 0 0]\n",
      "False\n",
      "y =  [10  8  7  7  7 14 14  3 11  7  1 14  3 11  1]\n",
      "p =  [10  7  7 14  7  7  7  0  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [10  7  7 14  7  1 14 14  1 14  3  0  0  0  0]\n",
      "p =  [10  7 11  0  7  1  2 14  0  0  0  0  0  0  0]\n",
      "False\n",
      "y =  [10  7 11 11  0  7 10  7  0  7  7  2 14  0  7]\n",
      "p =  [11 11 11 11  0  7  7  7 14  7 14 14  0  0  0]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for p,y in zip(predicts_test, Y_sent_vec_test) :\n",
    "    print('y = ', y[0:15])\n",
    "    print('p = ', p[0:15])\n",
    "    print(sum(p==y)==max_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "#from sklearn.linear_model import LogisticRegression, LinearRegression, Lars, RidgeCV\n",
    "#from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split, cross_val_score\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import gc\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['алматыға', 'аулада', 'балалар', 'барды', 'басталды', 'болып',\n",
       "       'біз', 'жүр', 'кітап', 'күн', 'мектепте', 'мен', 'ойнап', 'ол',\n",
       "       'отырмын', 'оқып', 'сабақ', 'тауға', 'тұр', 'шуақты', 'шығамыз'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lang(lang_code):\n",
    "    ds=pd.read_csv('lang_codes_dic.csv',';')\n",
    "    try:\n",
    "        return ds[ds.Code==lang_code].iloc[0,1]\n",
    "    except:\n",
    "        return 'Undefined'\n",
    "\n",
    "\n",
    "#vec encoding of words\n",
    "def alpha_vec2(w, mx, max_word_len, dic):\n",
    "    vec=np.zeros((max_word_len,len(dic)))    \n",
    "    for i in range(0, len(w)):\n",
    "        #print(i,w[i])\n",
    "        vec[i]=mx[dic.index(w[i])]\n",
    "        \n",
    "    vec=vec.astype('float16').flatten()\n",
    "    vec[vec==np.inf]=0 \n",
    "    vec[vec==-np.inf]=0        \n",
    "    return vec\n",
    "\n",
    "\n",
    "\n",
    "#ordinal encoding of words\n",
    "def alpha_vec2ord(w, max_word_len):\n",
    "    vec=np.zeros(max_word_len)    \n",
    "    for i in range(0, len(w)):        \n",
    "        vec[i]=ord(w[i])    \n",
    "    return vec.astype('int')\n",
    "\n",
    "#ordinal decoding of words\n",
    "def decode_vec(vec):\n",
    "    w=''.join([chr(int(v)) for v in vec if v!=0])    \n",
    "    return w.strip()\n",
    "\n",
    "def lemm_model(dictionary_file):\n",
    "    #load data\n",
    "    lex = pd.read_csv('DS_lemm/'+ dictionary_file,'\\t', encoding='utf8', names=['Lemma','Word_form'], keep_default_na=False)\n",
    "    lang_code=dictionary_file[dictionary_file.index('-')+1:-4]\n",
    "    lang=get_lang(lang_code)\n",
    "    print('Language: ', lang, lang_code)\n",
    "    number_words=lex.shape[0]\n",
    "    \n",
    "    X_lex=lex['Word_form'].str.strip()\n",
    "    X_lex=X_lex.values\n",
    "    \n",
    "    Y_lex=lex['Lemma'].str.strip()\n",
    "    Y_lex=Y_lex.values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_lex, Y_lex, test_size=0.1, random_state=42)\n",
    "    \n",
    "    #get max word length\n",
    "    max_word_len=max(max([len(w) for w in Y_lex]),max([len(w) for w in X_lex]))\n",
    "    \n",
    "    #Char2vec model\n",
    "    vectorizer = TfidfVectorizer(lowercase=False, analyzer='char')\n",
    "    X = vectorizer.fit_transform(X_lex)\n",
    "    dic=vectorizer.get_feature_names()#letter dictionary\n",
    "    num_letters=len(dic)\n",
    "    mx=X.T.dot(X)#letter cooccurence matrix\n",
    "    mx=mx.toarray()\n",
    "    \n",
    "    #Vectorize\n",
    "    X_lex_vec_train=[alpha_vec2(w, mx, max_word_len, dic) for w in X_train]\n",
    "    Y_lex_vec_train=[alpha_vec2ord(w, max_word_len) for w in y_train]\n",
    "    \n",
    "    X_lex_vec_test=[alpha_vec2(w, mx, max_word_len, dic) for w in X_test]\n",
    "    Y_lex_vec_test=[alpha_vec2ord(w, max_word_len) for w in y_test]\n",
    "    \n",
    "    #Build model\n",
    "    best_model=ExtraTreesClassifier(n_estimators=10, n_jobs=5, criterion='entropy', bootstrap=True)\n",
    "    \n",
    "    best_model.fit(X_lex_vec_train, Y_lex_vec_train)\n",
    "    \n",
    "    #Test\n",
    "    predicts_test=best_model.predict(X_lex_vec_test)\n",
    "    predicts_train=best_model.predict(X_lex_vec_train)\n",
    "    test_acc=sum([sum(p==y)==max_word_len for p,y in zip(predicts_test, Y_lex_vec_test)])/len(predicts_test)\n",
    "    train_acc=sum([sum(p==y)==max_word_len for p,y in zip(predicts_train, Y_lex_vec_train)])/len(predicts_train)\n",
    "    \n",
    "    #Return results\n",
    "    return test_acc, train_acc, max_word_len, num_letters, number_words, lang, lang_code, X_test, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
